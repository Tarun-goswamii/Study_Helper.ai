An advanced AI-powered assitance that can process **text, audio, images, and documents** using Retrieval Augmented Generation (RAG) with vector search capabilities.

## ✨ Features

### 🎯 **study_helper.ai**
- **📝 Text Chat** - Natural language conversations
- **🎵 Audio Processing** - Speech-to-text transcription and analysis
  
- **🖼️ Image Processing** - OCR text extraction + AI-powered descriptions
- **📄 Document Processing** - PDF, Word, TXT file content extraction

### 🔍 **Advanced AI Capabilities**
- **Vector Search** - Semantic similarity with Qdrant database
- **Google Gemini Integration** - Advanced AI responses
- **RAG System** - Retrieval Augmented Generation
- **Async Processing** - Fast multi-modal content handling
- **Smart Context** - Combines information from all modalities

### 🌐 **Web Interface**
- **Drag & Drop Upload** - Easy file handling
- **Real-time Processing** - Live chat interface
- **Statistics Dashboard** - Usage analytics
- **Conversation History** - Session memory
- **Responsive Design** - Works on desktop and mobile

## 🚀 Quick Start

### 1. **Setup Environment**
```bash
# Run the automated setup
setup_multimodal.bat
```

### 2. **Configure API Keys**
Edit `.env` file:
```env
GEMINI_API_KEY=your-actual-gemini-api-key
QDRANT_API_KEY=your-qdrant-cloud-api-key
```

### 3. **Launch Chatbot**
```bash
# Quick start with tests
python lightweight_interface.py

# Or directly launch web interface
python multimodal_web_interface.py
```

### 4. **Open Browser**
Visit: **http://localhost:5000**

## 📦 Installation

### **Automated Setup (Recommended)**
```bash
setup_multimodal.bat
```

### **Manual Installation**
```bash
# Create virtual environment
python -m venv multimodal_env
multimodal_env\Scripts\activate.bat

# Install dependencies
pip install -r multimodal_requirements.txt

# Configure environment
copy .env.example .env
# Edit .env with your API keys
```

## 🎮 Usage Examples

### **Text Chat**
```
User: "Explain how vector search works"
Bot: "Vector search uses high-dimensional embeddings to find semantically similar content..."
```

### **Image Upload + Question**
```
1. Upload an image
2. Ask: "What do you see in this image?"
3. Get AI-powered description + OCR text extraction
```

### **Document Analysis**
```
1. Upload PDF/Word document
2. Ask: "Summarize this document"
3. Get intelligent summary with key insights
```

### **Audio Transcription**
```
1. Upload audio file (MP3, WAV, etc.)
2. Get speech-to-text transcription
3. Ask follow-up questions about the content
```

### **Multi-Modal Combination**
```
1. Upload image + document + ask text question
2. Get comprehensive response using all inputs
3. AI combines information from all modalities
```

## 🏗️ Architecture

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Web Interface │────│  Flask Backend  │────│ Multi-Modal Bot │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                                        │
                       ┌─────────────────────────────────┼─────────────────────────────────┐
                       │                                 │                                 │
              ┌─────────▼─────────┐              ┌──────▼──────┐                ┌─────────▼─────────┐
              │   Audio Processor │              │   Video     │                │   Image Processor │
              │  - Speech-to-Text │              │  Processor  │                │  - OCR Extraction │
              │  - Quality Analysis│              │ - Frame Ext │                │  - AI Description │
              └───────────────────┘              │ - Detection │                └───────────────────┘
                                                └─────────────┘
                       ┌─────────────────────────────────┼─────────────────────────────────┐
                       │                                 │                                 │
              ┌─────────▼─────────┐              ┌──────▼──────┐                ┌─────────▼─────────┐
              │ Document Processor│              │   Vector    │                │   Google Gemini   │
              │  - PDF Extraction │              │   Search    │                │  - AI Responses   │
              │  - Word Parsing   │              │  (Qdrant)   │                │  - Vision API     │
              └───────────────────┘              └─────────────┘                └───────────────────┘
```

## 🔧 Configuration

### **Environment Variables (.env)**
```env
# AI Services
GEMINI_API_KEY=your-gemini-api-key
QDRANT_API_KEY=your-qdrant-api-key

# Qdrant Configuration  
QDRANT_HOST=localhost
QDRANT_PORT=6333

# File Upload Settings
MAX_FILE_SIZE=100
UPLOAD_FOLDER=uploads

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True
SECRET_KEY=your-secret-key
```

### **Supported File Types**
- **Audio**: MP3, WAV, OGG, M4A, FLAC 
- **Images**: PNG, JPG, JPEG, GIF, BMP, TIFF
- **Documents**: PDF, DOCX, DOC, TXT

## 🧪 Testing

### **Component Tests**
```bash
python quick_start_multimodal.py
```

### **Manual Testing**
1. **Text**: Ask "What are your capabilities?"
2. **Audio**: Upload speech recording
4. **Image**: Upload screenshot or photo
5. **Document**: Upload PDF or Word file
6. **Multi-Modal**: Combine multiple inputs

## 📊 Features Comparison

| Feature | Basic Chatbot | Multi-Modal RAG |
|---------|---------------|-----------------|
| Text Chat | ✅ | ✅ |
| Audio Processing | ❌ | ✅ |
| Image Understanding | ❌ | ✅ |
| Document Processing | ❌ | ✅ |
| Vector Search | ❌ | ✅ |
| Context Memory | ❌ | ✅ |
| Multi-Modal Fusion | ❌ | ✅ |

## 🐛 Troubleshooting

### **Common Issues**

**1. PyAudio Installation Error**
```bash
# Install Visual C++ Build Tools first
# Then: pip install pyaudio
```

**2. Tesseract OCR Missing**
```bash
# Download and install Tesseract OCR
# Add to PATH: C:\Program Files\Tesseract-OCR
```

**3. Gemini API Errors**
- Check API key validity
- Verify internet connection
- Ensure proper model access

**4. File Upload Fails**
- Check file size limits (100MB default)
- Verify file format support
- Ensure uploads folder exists

### **Debug Mode**
```bash
# Enable debug logging
FLASK_DEBUG=True python multimodal_web_interface.py
```

## 🔮 Advanced Usage

### **Custom Knowledge Base**
```python
# Add custom knowledge to the chatbot
chatbot.knowledge_base.append({
    "text": "Your custom knowledge",
    "category": "custom",
    "keywords": ["keyword1", "keyword2"]
})
```

### **API Integration**
```python
# Use programmatically
from multimodal_rag_chatbot import MultiModalRAGChatbot, MultiModalInput

chatbot = MultiModalRAGChatbot()
input_data = MultiModalInput(text="Hello", image_data=image_bytes)
result = process_multimodal_sync(chatbot, input_data)
```

## 📈 Performance

- **Text Processing**: ~0.1s response time
- **Audio Transcription**: ~2-5s for 1-minute audio
- **Image Analysis**: ~1-3s per image
- **Document Parsing**: ~1-2s per page

## 🤝 Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -am 'Add feature'`
4. Push branch: `git push origin feature-name`
5. Submit pull request

## 📄 License

This project is licensed under the MIT License - see the LICENSE file for details.

## 🙏 Acknowledgments

- **Google Gemini** - AI capabilities
- **Qdrant** - Vector search database
- **Sentence Transformers** - Text embeddings
- **OpenCV** - Computer vision
- **Flask** - Web framework

---

## 🎉 Ready to Go!

Your multi-modal RAG chatbot is now ready to handle any type of input - text, audio, video, images, and documents - all with intelligent AI responses powered by vector search!

**Start chatting**: http://localhost:5000 🚀
